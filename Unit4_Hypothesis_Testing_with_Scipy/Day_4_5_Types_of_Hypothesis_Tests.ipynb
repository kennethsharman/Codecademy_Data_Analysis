{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Types of Hypothesis Test\n",
    "When we are trying to compare datasets, we often need a way to be confident knowing if datasets are significantly different from each other.\n",
    "\n",
    "In this lesson, you will learn how about how we can use hypothesis testing to answer these questions. There are several different types of hypothesis tests for the various scenarios you may encounter. Luckily, SciPy has built-in functions that perform all of these tests for us, normally using just one line of code.\n",
    "\n",
    "For numerical data, we will cover:\n",
    "\n",
    "    One Sample T-Tests\n",
    "    Two Sample T-Tests\n",
    "    ANOVA\n",
    "    Tukey Tests\n",
    "    For categorical data, we will cover:\n",
    "\n",
    "    Binomial Tests\n",
    "    Chi Square\n",
    "After this lesson, you will have a wide range of tools in your arsenal to find meaningful correlations in data.\n",
    "\n",
    "### 1 Sample T-Testing\n",
    "Let's imagine the fictional business BuyPie, which sends ingredients for pies to your household, so that you can make them from scratch. Suppose that a product manager wants the average age of visitors to BuyPie.com to be 30. In the past hour, the website had 100 visitors and the average age was 31. Are the visitors too old? Or is this just the result of chance and a small sample size?\n",
    "\n",
    "We can test this using a univariate T-test. A univariate T-test compares a sample mean to a hypothetical population mean. It answers the question \"What is the probability that the sample came from a distribution with the desired mean?\"\n",
    "\n",
    "When we conduct a hypothesis test, we want to first create a null hypothesis, which is a prediction that there is no significant difference. The null hypothesis that this test examines can be phrased as such: \"The set of samples belongs to a population with the target mean\".\n",
    "\n",
    "The result of the 1 Sample T Test is a p-value, which will tell us whether or not we can reject this null hypothesis. Generally, if we receive a p-value of less than 0.05, we can reject the null hypothesis and state that there is a significant difference.\n",
    "\n",
    "SciPy has a function called ttest_1samp, which performs a 1 Sample T-Test for you.\n",
    "\n",
    "ttest_1samp requires two inputs, a distribution of values and an expected mean:\n",
    "\n",
    "tstat, pval = ttest_1samp(example_distribution, expected_mean)\n",
    "print pval\n",
    "It also returns two outputs: the t-statistic (which we won't cover in this course), and the p-value — telling us how confident we can be that the sample of values came from a distribution with the mean specified."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have provided a small dataset called ages, representing the ages of customers to BuyPie.com in the past hour.\n",
    "\n",
    "First, print out ages to the console and examine the numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[32. 34. 29. 29. 22. 39. 38. 37. 38. 36. 30. 26. 22. 22.]\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import ttest_1samp\n",
    "import numpy as np\n",
    "\n",
    "ages = np.array([32., 34., 29., 29., 22., 39., 38., 37., 38., 36., 30., 26., 22., 22.])\n",
    "print(ages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even with a small dataset like this, it is hard to make judgments from just looking at the numbers.\n",
    "\n",
    "To understand the data better, let's look at the mean. Calculate the mean of ages using np.mean. Store it in a variable called ages_mean and print it out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31.0\n"
     ]
    }
   ],
   "source": [
    "ages_mean = np.mean(ages)\n",
    "print(ages_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use ttest_1samp with ages to see what p-value the experiment returns for this distribution, where we expect the mean to be 30.\n",
    "\n",
    "Store the p-value in a variable called pval. Remember that it is the second output of the ttest_1samp function. We don't use the first output, the t-statistic, so you can store it in a variable with whatever name you'd like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5605155888171379\n"
     ]
    }
   ],
   "source": [
    "tstat, pval = ttest_1samp(ages, 30.)\n",
    "print(pval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One Sample T-Test II\n",
    "In the last exercise, we got a p-value that was much higher than 0.05, so we cannot reject the null hypothesis. Does this mean that if we wait for more visitors to BuyPie, the average age would definitely be 30 and not 31? Not necessarily. In fact, in this case, we know that the mean of our sample was 31.\n",
    "\n",
    "P-values give us an idea of how confident we can be in a result. Just because we don’t have enough data to detect a difference doesn’t mean that there isn’t one. Generally, the more samples we have, the smaller a difference we’ll be able to detect. You can learn more about the exact relationship between the number of samples and detectable differences in the Sample Size Determination course.\n",
    "\n",
    "To gain some intuition on how our confidence levels can change, let's explore some distributions with different means and how our p-values from the 1 Sample T-Tests change."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have loaded a dataset daily_visitors into the editor that represents the ages of visitors to BuyPie.com in the last 1000 days. Each entry daily_visitors[i] is an array of entries representing the age per visitor to the website on day i.\n",
    "\n",
    "We predicted that the average age would be 30, and we want to know if the actual data differs from that.\n",
    "\n",
    "We have made a for loop that goes through the 1000 inner lists. Inside this loop, perform a 1 Sample T-Test with each day of data (daily_visitors[i]). For now, just print out the p-value from each test.\n",
    "\n",
    "## NOTE: Meaning of pval\n",
    "If we get a pval < 0.05, we can conclude that it is unlikely that our sample has a true mean of 30. Thus, the hypothesis test has correctly rejected the null hypothesis, and we call that a correct result.\n",
    "\n",
    "Every time we get a correct result within the 1000 experiments, add 1 to correct_results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correct_results = 0 # Start the counter at 0\n",
    "\n",
    "# daily_visitors = np.genfromtxt(\"daily_visitors.csv\", delimiter=\",\")\n",
    "\n",
    "# for i in range(1000): # 1000 experiments\n",
    "  # tstatistic, pval = ttest_1samp(daily_visitors[i], 30)\n",
    "  # print pval\n",
    "  # if pval<0.05:\n",
    "    # correct_results += 1\n",
    "# print \"We correctly recognized that the distribution was different in \" + str(correct_results)\\\n",
    "# + \" out of 1000 experiments.\"\n",
    "# print \"We correctly recognized that the distribution was different in \" + str(correct_results) \\\n",
    "# + \" out of 1000 experiments.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 Sample T-Test\n",
    "Suppose that last week, the average amount of time spent per visitor to a website was 25 minutes. This week, the average amount of time spent per visitor to a website was 28 minutes. Did the average time spent per visitor change? Or is this part of natural fluctuations?\n",
    "\n",
    "One way of testing whether this difference is significant is by using a 2 Sample T-Test. A 2 Sample T-Test compares two sets of data, which are both approximately normally distributed.\n",
    "\n",
    "The null hypothesis, in this case, is that the two distributions have the same mean.\n",
    "\n",
    "We can use SciPy's ttest_ind function to perform a 2 Sample T-Test. It takes the two distributions as inputs and returns the t-statistic (which we don't use), and a p-value. If you can't remember what a p-value is, refer to the earlier exercise on univariate t-tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "week1 = np.array([ 23.90506824, 26.67631982, 27.27433886, 24.25757125, 32.40423483,\n",
    "  39.56919357, 23.07010059, 29.82068109, 27.59433809, 28.05639569,\n",
    "  27.06757262, 30.41192979, 25.71358554, 24.94294823, 28.23123807,\n",
    "  24.95337555, 18.51231639, 27.46234762, 28.38016611, 13.91205901,\n",
    "  29.02615866, 26.90746774, 22.8677726, 24.8938289, 25.96947935,\n",
    "  26.86869621, 20.72676456, 27.35988314, 20.68408581, 21.19846143,\n",
    "  16.25800931, 23.92517681, 24.47923229, 29.47050863, 27.28425372,\n",
    "  26.93339272, 28.61026924, 18.88377042, 33.65468651, 25.69470077,\n",
    "  20.98291356, 22.69700387, 28.60278855, 21.36000443, 30.77685156,\n",
    "  20.83415999, 23.79367158, 19.7556718, 29.54421084, 20.1433138 ])\n",
    "week2 = [ 18.63431907, 31.28788036, 34.96797943, 21.81678117, 28.21619974,\n",
    "  39.39313736, 35.52223207, 27.54222109, 33.64395433, 25.31673581,\n",
    "  28.81392191, 30.7358016, 26.37241881, 26.0945555, 26.34073477,\n",
    "  19.42196017, 32.58797652, 24.84001926, 28.93348335, 20.43667584,\n",
    "  22.72495967, 32.31728012, 35.384306, 29.66709637, 24.53512973,\n",
    "  30.91406007, 19.56117513, 24.90816833, 30.13163726, 31.47466199,\n",
    "  27.77683598, 16.51307462, 35.0770162, 31.74818107, 36.36053496,\n",
    "  27.70500593, 29.49869936, 27.65575346, 37.18504075, 25.16055104,\n",
    "  29.26553553, 38.22163057, 28.92102091, 24.8215439, 38.30155495,\n",
    "  34.76020645, 22.26869162, 28.82593733, 32.00975127, 36.46437665]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've created two distributions representing the time spent per visitor to BuyPie.com last week, week1, and the time spent per visitor to BuyPie.com this week, week2.\n",
    "\n",
    "Find the means of these two distributions. Store them in week1_mean and week2_mean. Print them to the console."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25.4480593952\n",
      "29.0215681076\n"
     ]
    }
   ],
   "source": [
    "week1_mean = np.mean(week1)\n",
    "week2_mean = np.mean(week2)\n",
    "print(week1_mean)\n",
    "print(week2_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the standard deviations of these two distributions. Store them in week1_std and week2_std. Print them to the console."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.531693386680561\n",
      "5.497966708987187\n"
     ]
    }
   ],
   "source": [
    "week1_std = np.std(week1)\n",
    "week2_std = np.std(week2)\n",
    "print(week1_std)\n",
    "print(week2_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run a 2 Sample T-Test using the SciPy function ttest_ind.\n",
    "\n",
    "Save the p-value in a variable called pval and print it out. Does this value make sense, knowing what you know about these datasets?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000676767690454633\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import ttest_ind\n",
    "\n",
    "tstatstic, pval = ttest_ind(week1, week2)\n",
    "print(pval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dangers of Multiple T-Tests\n",
    "Suppose that we own a chain of stores that sell ants, called VeryAnts. There are three different locations: A, B, and C. We want to know if the average ant sales over the past year are significantly different between the three locations.\n",
    "\n",
    "At first, it seems that we could perform T-tests between each pair of stores.\n",
    "\n",
    "We know that the p-value is the probability that we incorrectly reject the null hypothesis on each t-test. The more t-tests we perform, the more likely that we are to get a false positive, a Type I error.\n",
    "\n",
    "For a p-value of 0.05, if the null hypothesis is true then the probability of obtaining a significant result is 1 – 0.05 = 0.95. When we run another t-test, the probability of still getting a correct result is 0.95 * 0.95, or 0.9025. That means our probability of making an error is now close to 10%! This error probability only gets bigger with the more t-tests we do."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have created samples a, b, and c, representing the sales at VeryAnts at locations A, B, and C, respectively. We want to see if there's a significant difference in sales between the three locations.\n",
    "\n",
    "Explore datasets a, b, and c by finding and printing the means and standard deviations of each one. Store the means in variables called a_mean, b_mean, and c_mean. Store the standard deviations in variables called a_std, b_std, and c_std.\n",
    "\n",
    "Perform a 2-Sample T-test between each pair of location data.\n",
    "\n",
    "Store the p-values in variables called a_b_pval, a_c_pval, and b_c_pval. Print them to the console.\n",
    "\n",
    "Store the probability of error in a variable called error_prob. Print it out to the console."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = np.genfromtxt(\"store_a.csv\",  delimiter=\",\")\n",
    "# b = np.genfromtxt(\"store_b.csv\",  delimiter=\",\")\n",
    "# c = np.genfromtxt(\"store_c.csv\",  delimiter=\",\")\n",
    "\n",
    "# a_mean = np.mean(a)\n",
    "# a_std = np.std(a)\n",
    "\n",
    "# b_mean = np.mean(b)\n",
    "# b_std = np.std(b)\n",
    "\n",
    "# c_mean = np.mean(c)\n",
    "# c_std = np.std(c)\n",
    "\n",
    "# print(a_mean, a_std)\n",
    "# print(b_mean, b_std)\n",
    "# print(c_mean, c_std)\n",
    "\n",
    "# t1, a_b_pval = ttest_ind(a, b)\n",
    "# t2, a_c_pval = ttest_ind(a, c)\n",
    "# t3, b_c_pval = ttest_ind(b, c)\n",
    "\n",
    "# print(a_b_pval)\n",
    "# print(a_c_pval)\n",
    "# print(b_c_pval)\n",
    "\n",
    "# error_prob = 1-0.95**3\n",
    "# print(error_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ANOVA\n",
    "In the last exercise, we saw that the probability of making a Type I error got dangerously high as we performed more t-tests.\n",
    "\n",
    "When comparing more than two numerical datasets, the best way to preserve a Type I error probability of 0.05 is to use ANOVA. ANOVA (Analysis of Variance) tests the null hypothesis that all of the datasets have the same mean. If we reject the null hypothesis with ANOVA, we're saying that at least one of the sets has a different mean; however, it does not tell us which datasets are different.\n",
    "\n",
    "We can use the SciPy function f_oneway to perform ANOVA on multiple datasets. It takes in each dataset as a different input and returns the t-statistic and the p-value. For example, if we were comparing scores on a videogame between math majors, writing majors, and psychology majors, we could run an ANOVA test with this line:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fstat, pval = f_oneway(scores_mathematicians, scores_writers, scores_psychologists)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The null hypothesis, in this case, is that all three populations have the same mean score on this videogame. If we reject this null hypothesis (if we get a p-value less than 0.05), we can say that we are reasonably confident that a pair of datasets is significantly different. After using only ANOVA, we can't make any conclusions on which two populations have a significant difference.\n",
    "\n",
    "Let's look at an example of ANOVA in action.\n",
    "\n",
    "Perform an ANOVA test on a, b, and c and store the p-value in a variable called pval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import ttest_ind\n",
    "from scipy.stats import f_oneway\n",
    "import numpy as np\n",
    "\n",
    "# a = np.genfromtxt(\"store_a.csv\",  delimiter=\",\")\n",
    "# b = np.genfromtxt(\"store_b.csv\",  delimiter=\",\")\n",
    "# c = np.genfromtxt(\"store_c.csv\",  delimiter=\",\")\n",
    "\n",
    "# fstat, pval = f_oneway(a, b, c)\n",
    "# print(pval)\n",
    "\n",
    "# b = np.genfromtxt(\"store_b_new.csv\",  delimiter=\",\")\n",
    "\n",
    "# fstat, pval = f_oneway(a, b, c)\n",
    "# print(pval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assumptions of Numerical Hypothesis Tests\n",
    "Before we use numerical hypothesis tests, we need to be sure that the following things are true:\n",
    "\n",
    "1. THE SAMPLES SHOULD EACH BE NORMALLY DISTRIBUTED...ISH\n",
    "Data analysts in the real world often still perform hypothesis on sets that aren't exactly normally distributed. What is more important is to recognize if there is some reason to believe that a normal distribution is especially unlikely. If your dataset is definitively not normal, the numerical hypothesis tests won't work as intended.\n",
    "\n",
    "2. THE POPULATION STANDARD DEVIATIONS OF THE GROUPS SHOULD BE EQUAL\n",
    "For ANOVA and 2-Sample T-Tests, using datasets with standard deviations that are significantly different from each other will often obscure the differences in group means.\n",
    "\n",
    "To check for similarity between the standard deviations, it is normally sufficient to divide the two standard deviations and see if the ratio is \"close enough\" to 1. \"Close enough\" may differ in different contexts but generally staying within 10% should suffice.\n",
    "\n",
    "3. THE SAMPLES MUST BE INDEPENDENT\n",
    "When comparing two or more datasets, the values in one distribution should not affect the values in another distribution. In other words, knowing more about one distribution should not give you any information about any other distribution.\n",
    "\n",
    "Here are some examples where it would seem the samples are not independent:\n",
    "\n",
    "    the number of goals scored per soccer player before, during, and after undergoing a rigorous training regimen\n",
    "    a group of patients' blood pressure levels before, during, and after the administration of a drug\n",
    "It is important to understand your datasets before you begin conducting hypothesis tests on it so that you know you are choosing the right test.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tukey's Range Test\n",
    "Let's say that we have performed ANOVA to compare three sets of data from the three VeryAnts stores. We received the result that there is some significant difference between datasets.\n",
    "\n",
    "Now, we have to find out which datasets are different.\n",
    "\n",
    "We can perform a Tukey's Range Test to determine the difference between datasets.\n",
    "\n",
    "If we feed in three datasets, such as the sales at the VeryAnts store locations A, B, and C, Tukey's Test can tell us which pairs of locations are distinguishable from each other.\n",
    "\n",
    "The function to perform Tukey's Range Test is pairwise_tukeyhsd, which is found in statsmodel, not scipy. We have to provide the function with one list of all of the data and a list of labels that tell the function which elements of the list are from which set. We also provide the significance level we want, which is usually 0.05.\n",
    "\n",
    "For example, if we were looking to compare mean scores of movies that are dramas, comedies, or documentaries, we would make a call to pairwise_tukeyhsd like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# movie_scores = np.concatenate([drama_scores, comedy_scores, documentary_scores])\n",
    "# labels = ['drama'] * len(drama_scores) + ['comedy'] * len(comedy_scores) + ['documentary'] * len(documentary_scores)\n",
    "\n",
    "# tukey_results = pairwise_tukeyhsd(movie_scores, labels, 0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It will return a table of information, telling you whether or not to reject the null hypothesis for each pair of datasets.\n",
    "\n",
    "We have concatenated the sales data in lists a, b, and c and put it into list v. We have also provided a labels list that keeps track of which elements of v come from a, b, or c.\n",
    "\n",
    "Use pairwise_tukeyhsd with these two lists and 0.05 (the desired significance level) as inputs. Store the results in a variable called tukey_results.\n",
    "\n",
    "Print tukey_results to the console."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "from scipy.stats import f_oneway\n",
    "import numpy as np\n",
    "\n",
    "# a = np.genfromtxt(\"store_a.csv\",  delimiter=\",\")\n",
    "# b = np.genfromtxt(\"store_b.csv\",  delimiter=\",\")\n",
    "# c = np.genfromtxt(\"store_c.csv\",  delimiter=\",\")\n",
    "\n",
    "# stat, pval = f_oneway(a, b, c)\n",
    "# print pval\n",
    "\n",
    "# Using our data from ANOVA, we create v and l\n",
    "# v = np.concatenate([a, b, c])\n",
    "# labels = ['a'] * len(a) + ['b'] * len(b) + ['c'] * len(c)\n",
    "\n",
    "# tukey_results = pairwise_tukeyhsd(v, labels, 0.05)\n",
    "# print(tukey_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binomial Test\n",
    "Let's imagine that we are analyzing the percentage of customers who make a purchase after visiting a website. We have a set of 1000 customers from this month, 58 of whom made a purchase. Over the past year, the number of visitors per every 1000 who make a purchase hovers consistently at around 72. Thus, our marketing department has set our target number of purchases per 1000 visits to be 72. We would like to know if this month's number, 58, is a significant difference from that target or a result of natural fluctuations.\n",
    "\n",
    "How do we begin comparing this, if there's no mean or standard deviation that we can use? The data is divided into two discrete categories, \"made a purchase\" and \"did not make a purchase\".\n",
    "\n",
    "So far, we have been working with numerical datasets. The tests we have looked at, the 1- and 2-Sample T-Tests, ANOVA, and Tukey's Range test, will not work if we can't find the means of our distributions and compare them.\n",
    "\n",
    "If we have a dataset where the entries are not numbers, but categories instead, we have to use different methods.\n",
    "\n",
    "To analyze a dataset like this, with two different possibilities for entries, we can use a Binomial Test. A Binomial Test compares a categorical dataset to some expectation.\n",
    "\n",
    "Examples include:\n",
    "\n",
    "    Comparing the actual percent of emails that were opened to the quarterly goals\n",
    "    Comparing the actual percentage of respondents who gave a certain survey response to the expected survey response\n",
    "    Comparing the actual number of heads from 1000 coin flips of a weighted coin to the expected number of heads\n",
    "The null hypothesis, in this case, would be that there is no difference between the observed behavior and the expected behavior. If we get a p-value of less than 0.05, we can reject that hypothesis and determine that there is a difference between the observation and expectation.\n",
    "\n",
    "SciPy has a function called binom_test, which performs a Binomial Test for you.\n",
    "\n",
    "binom_test requires three inputs, the number of observed successes, the number of total trials, and an expected probability of success. For example, with 1000 coin flips of a fair coin, we would expect a \"success rate\" (the rate of getting heads), to be 0.5, and the number of trials to be 1000. Let's imagine we get 525 heads. Is the coin weighted? This function call would look like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pval = binom_test(525, n=1000, p=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It returns a p-value, telling us how confident we can be that the sample of values was likely to occur with the specified probability. If we get a p-value less than 0.05, we can reject the null hypothesis and say that it is likely the coin is actually weighted, and that the probability of getting heads is statistically different than 0.5.\n",
    "\n",
    "Suppose the goal of VeryAnts's marketing team this quarter was to have 6% of customers click a link that was emailed to them. They sent out a link to 10,000 customers and 510 clicked the link, which comes out to 5.1% instead of 6%. Did they do significantly worse than the target? Let's use a binomial test to answer this question.\n",
    "\n",
    "Use SciPy's binom_test function to calculate the p-value the experiment returns for this distribution, where we wanted the mean to be 6% of emails opened, or p=0.06, but only saw 5.1% of emails opened.\n",
    "\n",
    "Store the p-value in a variable called pval and print it out.\n",
    "\n",
    "For the next quarter, marketing has tried out a new email tactic, including puns in every line of every email. As a result, 590 people out of 10000 opened the link in the newest email.\n",
    "\n",
    "If we still wanted the mean to be 6% of emails opened, but now have 5.9% of emails opened, what is the new p-value. Save your results to the variable pval2\n",
    "\n",
    "Does this new p-value make sense?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00011592032724546606\n",
      "0.6891529835730346\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import binom_test\n",
    "\n",
    "pval = binom_test(510, n=10000, p=0.06)\n",
    "print(pval)\n",
    "\n",
    "pval2 = binom_test(590, n=10000, p=0.06)\n",
    "print(pval2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chi Square Test\n",
    "In the last exercise, we looked at data where customers visited a website and either made a purchase or did not make a purchase. What if we also wanted to track if visitors added any items to their shopping cart? With three discrete categories of data per dataset, we can no longer use a Binomial Test. If we have two or more categorical datasets that we want to compare, we should use a Chi Square test. It is useful in situations like:\n",
    "\n",
    "    An A/B test where half of users were shown a green submit button and the other half were shown a purple submit button. Was one group more likely to click the submit button?\n",
    "    Men and women were both given a survey asking \"Which of the following three products is your favorite?\" Did the men and women have significantly different preferences?\n",
    "In SciPy, you can use the function chi2_contingency to perform a Chi Square test.\n",
    "\n",
    "The input to chi2_contingency is a contingency table where:\n",
    "\n",
    "    The columns are each a different condition, such as men vs. women or Interface A vs. Interface B\n",
    "    The rows represent different outcomes, like \"Survey Response A\" vs. \"Survey Response B\" or \"Clicked a Link\" vs. \"Didn't Click\"\n",
    "This table can have as many rows and columns as you need.\n",
    "\n",
    "In this case, the null hypothesis is that there's no significant difference between the datasets. We reject that hypothesis, and state that there is a significant difference between two of the datasets if we get a p-value less than 0.05.\n",
    "\n",
    "The management at the VeryAnts ant store wants to know if their two most popular species of ants, the Leaf Cutter and the Harvester, vary in popularity between 1st, 2nd, and 3rd graders.\n",
    "\n",
    "We have created a table representing the different ants bought by the children in grades 1, 2, and 3 after the last big field trip to VeryAnts. Run the code to see what happens when we enter this table into SciPy's chi-square test.\n",
    "\n",
    "Does the resulting p-value mean that we should reject or accept the null hypothesis?\n",
    "\n",
    "A class of 40 4th graders comes into VeryAnts in the next week and buys 20 sets of Leaf Cutter ants and 20 sets of Harvester ants.\n",
    "\n",
    "Add this data to the contingency table, rerun the chi-square test, and see if there is now a low enough value to reject the null hypothesis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.15508230807673704\n",
      "0.002812834559546625\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "# Contingency table\n",
    "#         harvester |  leaf cutter\n",
    "# ----+------------------+------------\n",
    "# 1st gr | 30       |  10\n",
    "# 2nd gr | 35       |  5\n",
    "# 3rd gr | 28       |  12\n",
    "\n",
    "X = [[30, 10],\n",
    "     [35, 5],\n",
    "     [28, 12]]\n",
    "chi2, pval, dof, expected = chi2_contingency(X)\n",
    "print(pval)\n",
    "\n",
    "X = [[30, 10],\n",
    "     [35, 5],\n",
    "     [28, 12],\n",
    "     [20, 20]]\n",
    "chi2, pval, dof, expected = chi2_contingency(X)\n",
    "print(pval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
