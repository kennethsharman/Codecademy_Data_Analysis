{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NumPy: Basic Statistics\n",
    "\n",
    "### NumPy and Mean\n",
    "The first statistical concept we'll explore is mean, also commonly referred to as an average. The mean is a useful measurement to get the center of a dataset. NumPy has a built-in function to calculate the average or mean of arrays: np.mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "store_one = np.array([2, 5, 8, 3, 4, 10, 15, 5])\n",
    "store_two = np.array([3, 17, 18,  9,  2, 14, 10])\n",
    "store_three = np.array([7, 5, 4, 3, 2, 7, 7])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The beverage distributor, Wine Not? wants to calculate how many bottles of Bourdeaux it sells on average at three area wine sellers to determine whether or not it should increase its stock. The sales for the past week for each store are listed above.\n",
    "\n",
    "Find the average sales for each store, and save them to the variables store_one_avg, store_two_avg, and store_three_avg."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.5 10.428571428571429 5.0\n"
     ]
    }
   ],
   "source": [
    "store_one_avg = np.mean(store_one)\n",
    "store_two_avg = np.mean(store_two)\n",
    "store_three_avg = np.mean(store_three)\n",
    "\n",
    "print(store_one_avg, store_two_avg, store_three_avg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the average sales per week for each store. The boss says that we should increase what we stock, but only if the store's average sales are greater than 7 bottles per week.\n",
    "\n",
    "Save the store dataset variable name that fits this description to the variable best_seller."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_seller = store_two"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean and Logical Operations\n",
    "We can also use np.mean to calculate the percent of array elements that have a certain property.\n",
    "\n",
    "As we know, a logical operator will evaluate each item in an array to see if it matches the specified condition. If the item matches the given condition, the item will evaluate as True and equal 1. If it does not match, it will be False and equal 0.\n",
    "\n",
    "When np.mean calculates a logical statement, the resulting mean value will be equivalent to the total number of True items divided by the total array length.\n",
    "\n",
    "You're running an alumni reunion at your local college. You have a list of the names of each person in attendance and the year that they graduated.\n",
    "\n",
    "We've saved this list as a NumPy array to the variable class_year. Calculate the percent of attending alumni who graduated on and after 2005 and save your result to the variable millennials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.21\n"
     ]
    }
   ],
   "source": [
    "class_year = np.array([1967, 1949, 2004, 1997, 1953, 1950, 1958, 1974, 1987, 2006, 2013, 1978, 1951, 1998, 1996, 1952, 2005,\\\n",
    "                       2007, 2003, 1955, 1963, 1978, 2001, 2012, 2014, 1948, 1970, 2011, 1962, 1966, 1978, 1988, 2006, 1971,\\\n",
    "                       1994, 1978, 1977, 1960, 2008, 1965, 1990, 2011, 1962, 1995, 2004, 1991, 1952, 2013, 1983, 1955, 1957,\\\n",
    "                       1947, 1994, 1978, 1957, 2016, 1969, 1996, 1958, 1994, 1958, 2008, 1988, 1977, 1991, 1997, 2009, 1976,\\\n",
    "                       1999, 1975, 1949, 1985, 2001, 1952, 1953, 1949, 2015, 2006, 1996, 2015, 2009, 1949, 2004, 2010, 2011,\\\n",
    "                       2001, 1998, 1967, 1994, 1966, 1994, 1986, 1963, 1954, 1963, 1987, 1992, 2008, 1979, 1987])\n",
    "\n",
    "millennials = np.mean(class_year >= 2005)\n",
    "print(millennials)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating the Mean of 2D Arrays\n",
    "If we have a two-dimensional array, np.mean can calculate the means of the larger array as well as the interior values.\n",
    "\n",
    "Let's imagine a game of ring toss at a carnival. In this game, you have three different chances to get all three rings onto a stick. In our ring_toss array, each interior array (the arrays within the larger array) is one try, and each number is one ring toss. 1 represents a successful toss, 0 represents a fail.\n",
    "\n",
    "First, we can use np.mean to find the mean across all the arrays:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4444444444444444\n"
     ]
    }
   ],
   "source": [
    "ring_toss = np.array([[1, 0, 0], \n",
    "                          [0, 0, 1], \n",
    "                          [1, 0, 1]])\n",
    "print(np.mean(ring_toss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To find the means of each interior array, we specify axis 1 (the \"rows\"):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.33333333 0.33333333 0.66666667]\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(ring_toss, axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To find the means of each index position (i.e, mean of all 1st tosses, mean of all 2nd tosses, ...), we specifiy axis 0 (the \"columns\"):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.66666667 0.         0.66666667]\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(ring_toss, axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.\n",
    "In script.py, we've provided data about a trial for a new allergy medication, AllerGeeThatSucks! Five participants were asked to rate how drowsy the medication made them once a day for three days on a scale of one (least drowsy) to ten (most drowsy).\n",
    "\n",
    "Use np.mean to find the average level of drowsiness across all the trials and save the result to the variable total_mean.\n",
    "\n",
    "2.\n",
    "Use np.mean to find the average level of drowsiness across each day of the experiment and save to the variable trial_mean.\n",
    "\n",
    "3.\n",
    "Use np.mean to find the average level of drowsiness across for each individual patient to see if some were more sensitive to the drug than others and save it to the variable patient_mean.\n",
    "\n",
    "4.\n",
    "Print the variables for total_mean, trial_mean, and patient_mean on three separate lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Across all trials: 5.266666666666667\n",
      "Average across each day: [4.  5.6 6.2]\n",
      "Average for each patient: [4.33333333 3.         4.         8.66666667 6.33333333]\n"
     ]
    }
   ],
   "source": [
    "allergy_trials = np.array([[6, 1, 3, 8, 2], \n",
    "                           [2, 6, 3, 9, 8], \n",
    "                           [5, 2, 6, 9, 9]])\n",
    "\n",
    "total_mean = np.mean(allergy_trials)\n",
    "trial_mean = np.mean(allergy_trials, axis=1)\n",
    "patient_mean = np.mean(allergy_trials, axis=0)\n",
    "\n",
    "print('Average Across all trials:', total_mean)\n",
    "print('Average across each day:', trial_mean) \n",
    "print('Average for each patient:', patient_mean) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outliers\n",
    "As we can see, the mean is a helpful way to quickly understand different parts of our data. However, the mean is highly influenced by the specific values in our data set. What happens when one of those values is significantly different from the rest?\n",
    "\n",
    "Values that don’t fit within the majority of a dataset are known as outliers. It’s important to identify outliers because if they go unnoticed, they can skew our data and lead to error in our analysis (like determining the mean). They can also be useful in pointing out errors in our data collection.\n",
    "\n",
    "When we're able to identify outliers, we can then determine if they were due to an error in sample collection or whether or not they represent a significant but real deviation from the mean."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sorting and Outliers\n",
    "One way to quickly identify outliers is by sorting our data, Once our data is sorted, we can quickly glance at the beginning or end of an array to see if some values lie far beyond the expected range. We can use the NumPy function np.sort to sort our data.\n",
    "\n",
    "1.\n",
    "You've been tracking temperature data over the summer on your back porch, but realized that you placed your sensor right over a grill! Before you can use your data, you need to check to see if the heat from the grill caused any weird readings that could skew your data.\n",
    "\n",
    "First, sort the temps data array and save the sorted data to a sorted_temps variable.\n",
    "\n",
    "2.\n",
    "Now, print the sorted_temps array. What do we see? Did the grill, in fact, create outliers in our data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 85  85  85  85  85  86  86  86  86  86  86  86  87  87  87  87  87  87\n",
      "  87  88  88  88  88  88  88  88  88  89  89  90  90  90  90  90  90  90\n",
      "  90  91  91  91  92  92  92  92  92  93  93  93  93  93  94  94  94  94\n",
      "  94  94  94  95  95  96  96  96  96  96  96  97  97  97  97  97  98  98\n",
      "  98  98  98  98  99  99  99  99  99 100 101 101 187 191 195 196 198 199]\n"
     ]
    }
   ],
   "source": [
    "temps = np.array([86, 88, 94, 85, 97, 90, 87, 85, 94, 93, 92, 95, 98, 85, 94, 91, 97, 88, 87, 86, 99, 89, 89, 99, 88, 96,\\\n",
    "                  93, 96, 85, 88, 191, 95, 96, 87, 99, 93, 90, 86, 87, 100, 187, 98, 101, 101, 96, 94, 96, 87, 86, 92, 98,\\\n",
    "                  94, 98, 90, 99, 96, 99, 86, 97, 98, 86, 90, 86, 94, 91, 88, 196, 195,93, 97, 199, 87, 87, 90, 90, 98, 88,\\\n",
    "                  92, 97, 88, 85, 94, 88, 93, 198, 90, 91, 90, 92, 92])\n",
    "\n",
    "sorted_temps = np.sort(temps)\n",
    "print(sorted_temps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NumPy and Median\n",
    "Another key metric that we can use in data analysis is the median. The median is the middle value of a dataset that’s been ordered in terms of magnitude (from lowest to highest)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.5\n"
     ]
    }
   ],
   "source": [
    "# CSV file was used in example, so here is a basic example of np.median\n",
    "\n",
    "array = np.array([1,2,3,4,5,6,7,8,9,10])\n",
    "print(np.median(array))\n",
    "\n",
    "# More work was done with comparing the mean and median of an array generated from CSV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Percentiles, Part I\n",
    "As we know, the median is the middle of a dataset: it is the number for which 50% of the samples are below, and 50% of the samples are above. But what if we wanted to find a point at which 40% of the samples are below, and 60% of the samples are above?\n",
    "\n",
    "This type of point is called a percentile. The Nth percentile is defined as the point N% of samples lie below it. So the point where 40% of samples are below is called the 40th percentile. Percentiles are useful measurements because they can tell us where a particular value is situated within the greater dataset.\n",
    "\n",
    "Let's look at the following array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = [1, 2, 3, 4, 4, 4, 6, 6, 7, 8, 8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 11 numbers in the dataset. The 40th percentile will have 40% of the 10 remaining numbers below it (40% of 10 is 4) and 60% of the numbers above it (60% of 10 is 6). So in this example, the 40th percentile is 4.\n",
    "\n",
    "In NumPy, we can calculate percentiles using the function np.percentile, which takes two arguments: the array and the percentile to calculate.\n",
    "\n",
    "Here's how we would use NumPy to calculate the 40th percentile of array d:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.0\n"
     ]
    }
   ],
   "source": [
    "d = np.array([1, 2, 3, 4, 4, 4, 6, 6, 7,  8, 8])\n",
    "print(np.percentile(d, 40))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.\n",
    "The local public library wants to study how many hours a week their patrons use the computers. At the top of the script.py, we have included sample data from 11 users in a NumPy array.\n",
    "\n",
    "Use NumPy to find the 30th percentile of the sorted array and save it to a variable named thirtieth_percentile.\n",
    "\n",
    "2.\n",
    "Next, use NumPy to find the 70th percentile and save it to the variable seventieth_percentile.\n",
    "\n",
    "3.\n",
    "Print the 30th and 70th variables to the terminal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0 8.0\n"
     ]
    }
   ],
   "source": [
    "patrons = np.array([ 2, 6, 14, 4, 3, 9, 1, 11, 4, 2, 8])\n",
    "\n",
    "thirtieth_percentile = np.percentile(patrons, 30)\n",
    "\n",
    "seventieth_percentile = np.percentile(patrons, 70)\n",
    "\n",
    "print(thirtieth_percentile, seventieth_percentile)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Percentiles, Part II\n",
    "Some percentiles have specific names:\n",
    "\n",
    "The 25th percentile is called the first quartile\n",
    "The 50th percentile is called the median\n",
    "The 75th percentile is called the third quartile\n",
    "The minimum, first quartile, median, third quartile, and maximum of a dataset are called a five-number summary. This set of numbers is a great thing to compute when we get a new dataset.\n",
    "\n",
    "The difference between the first and third quartile is a value called the interquartile range. For example, say we have the following array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = [1, 2, 3, 4, 4, 4, 6, 6, 7, 8, 8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can calculate the 25th and 75th percentiles using np.percentile:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.5\n",
      "6.5\n"
     ]
    }
   ],
   "source": [
    "print(np.percentile(d, 25))\n",
    "print(np.percentile(d, 75))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then to find the interquartile range, we subtract the value of the 25th percentile from the value of the 75th:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0\n"
     ]
    }
   ],
   "source": [
    "print(6.5 - 3.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "50% of the dataset will lie within the interquartile range. The interquartile range gives us an idea of how spread out our data is. The smaller the interquartile range value, the less variance in our dataset. The greater the value, the larger the variance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.\n",
    "An online movie streaming company wants to know how many movies users watch in one week. At the top of the script.py, we have included sample data from 15 users in an array.\n",
    "\n",
    "Find the 25th and 75th percentiles, and save them to the corresponding variables: first_quarter and third_quarter.\n",
    "\n",
    "2.\n",
    "Create a variable named interquartile_range. Calculate the interquartile range and save it to this variable.\n",
    "\n",
    "3.\n",
    "Print the results of the 25th percentile, 75th percentile, and interquartile range to the terminal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 3.5 2.5\n"
     ]
    }
   ],
   "source": [
    "movies_watched = np.array([2, 3, 8, 0, 2, 4, 3, 1, 1, 0, 5, 1, 1, 7, 2])\n",
    "\n",
    "first_quarter = np.percentile(movies_watched, 25)\n",
    "third_quarter = np.percentile(movies_watched, 75)\n",
    "\n",
    "interquartile_range = third_quarter - first_quarter\n",
    "print(first_quarter, third_quarter, interquartile_range)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NumPy and Standard Deviation, Part I\n",
    "While the mean and median can tell us about the center of our data, they do not reflect the range of the data. That's where standard deviation comes in.\n",
    "\n",
    "Similar to the interquartile range, the standard deviation tells us the spread of the data. The larger the standard deviation, the more spread out our data is from the center. The smaller the standard deviation, the more the data is clustered around the mean.\n",
    "\n",
    "We can find the standard deviation of a dataset using the Numpy function np.std:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17.716909687891082\n"
     ]
    }
   ],
   "source": [
    "nums = np.array([65, 36, 52, 91, 63, 79])\n",
    "print(np.std(nums))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "pumpkin = np.array([68, 1820, 1420, 2062, 704, 1156, 1857, 1755, 2092, 1384])\n",
    "\n",
    "acorn_squash = np.array([20, 43, 99, 200, 12, 250, 58, 120, 230, 215])\n",
    "\n",
    "pumpkin_avg = np.mean(pumpkin)\n",
    "acorn_squash_avg = np.mean(acorn_squash)\n",
    "\n",
    "pumpkin_std = np.std(pumpkin)\n",
    "acorn_squash_std = np.std(acorn_squash)\n",
    "\n",
    "#winner = np.max(pumpkin_std, acorn_squash_std)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.\n",
    "You've been asked to judge your town's annual squash festival. The festival organizer gives you a list that includes all the weights for the two competitions that you're judging: pumpkins and acorn squash.\n",
    "\n",
    "Given the two data sets at the top of script.py, find the average weight for each competition and save them to the variables pumpkin_avg and acorn_squash_avg.\n",
    "\n",
    "2.\n",
    "Now, the rest of the judges want you to give them an idea of how representative the mean values are in relation to the entirety of the submissions. Calculate the standard deviation for each of the datasets to find and save them to the variables pumpkin_std and acorn_squash_std. Print them to the console to see their values.\n",
    "\n",
    "3.\n",
    "Determine the squash dataset that has the greater standard deviation and save it to the variable winner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "pumpkin = np.array([68, 1820, 1420, 2062, 704, 1156, 1857, 1755, 2092, 1384])\n",
    "\n",
    "acorn_squash = np.array([20, 43, 99, 200, 12, 250, 58, 120, 230, 215])\n",
    "\n",
    "pumpkin_avg = np.mean(pumpkin)\n",
    "acorn_squash_avg = np.mean(acorn_squash)\n",
    "\n",
    "pumpkin_std = np.std(pumpkin)\n",
    "acorn_squash_std = np.std(acorn_squash)\n",
    "\n",
    "if pumpkin_std > acorn_squash_std:\n",
    "  winner = pumpkin\n",
    "else:\n",
    "  winner = acorn_squash"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Review\n",
    "Let's review! In this lesson, you learned how to use NumPy to analyze single-variable datasets. Here's what we covered:\n",
    "\n",
    "Using the np.sort method to locate outliers.\n",
    "Calculating central positions of a dataset using np.mean and np.median.\n",
    "Understanding the spread of our data using percentiles and the interquartile range.\n",
    "Finding the standard deviation of a dataset using np.std.\n",
    "In our next lesson, we'll continue our exploration of NumPy and see how we can use it to analyze different statistical distributions. Follow the checkpoints below to practice what you just learned!\n",
    "\n",
    "A group of citizen scientists has been collecting data on rainfall in Seattle. They've presented their data to you in the form of monthly averages, measured in inches.\n",
    "\n",
    "Find the mean of the rainfall array and save it to the variable rain_mean.\n",
    "\n",
    "3.\n",
    "Find the median of the rainfall array and save it to the variable rain_median.\n",
    "\n",
    "4.\n",
    "Find the 25th and the 75th percentiles of the original rainfall array and save them to the arrays first_quarter and third_quarter, respectively.\n",
    "\n",
    "5.\n",
    "Calculate the interquartile range and save it to the variable, interquartile_range.\n",
    "\n",
    "6.\n",
    "Determine the standard deviation of the set and save it to the variable rain_std.\n",
    "\n",
    "7.\n",
    "Print the variables to the terminal to see your results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.895 2.81 1.6775 4.025 2.3475 1.5267312577311483\n"
     ]
    }
   ],
   "source": [
    "rainfall = np.array([5.21, 3.76, 3.27, 2.35, 1.89, 1.55, 0.65, 1.06, 1.72, 3.35, 4.82, 5.11])\n",
    "\n",
    "rain_mean = np.mean(rainfall)\n",
    "rain_median = np.median(rainfall)\n",
    "\n",
    "first_quarter = np.percentile(rainfall, 25)\n",
    "third_quarter = np.percentile(rainfall, 75)\n",
    "\n",
    "interquartile_range = (third_quarter - first_quarter)\n",
    "\n",
    "rain_std = np.std(rainfall)\n",
    "\n",
    "print(rain_mean, rain_median, first_quarter, third_quarter, \\\n",
    "      interquartile_range, rain_std)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
