{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "This lesson you will learn about aggregates in Pandas. An aggregate statistic is a way of creating a single number that describes a group of numbers. Common aggregate statistics incluse mean, median, or standard deviation.\n",
    "\n",
    "You will also learn how to rearrange a DataFrame into a pivot table, which is a great way to compare data across two dimensions.\n",
    "\n",
    "### Calculating Column Statistics\n",
    "In the previous lesson, you learned how to perform operations on each value in a column using apply.\n",
    "\n",
    "In this exercise, you will learn how to combine all of the values from a column for a single calculation.\n",
    "\n",
    "Some examples of this type of calculation include:\n",
    "\n",
    "The DataFrame customers contains the names and ages of all of your customers. You want to find the median age:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "print(customers.age)\n",
    ">> [23, 25, 31, 35, 35, 46, 62]\n",
    "print(customers.age.median())\n",
    ">> 35\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The DataFrame shipments contains address information for all shipments that you've sent out in the past year. You want to know how many different states you have shipped to (and how many shipments went to the same state)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nprint(shipments.state)\\n>> ['CA', 'CA', 'CA', 'CA', 'NY', 'NY', 'NJ', 'NJ', 'NJ', 'NJ', 'NJ', 'NJ', 'NJ']\\nprint(shipments.state.nunique())\\n>> 3\\n\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "print(shipments.state)\n",
    ">> ['CA', 'CA', 'CA', 'CA', 'NY', 'NY', 'NJ', 'NJ', 'NJ', 'NJ', 'NJ', 'NJ', 'NJ']\n",
    "print(shipments.state.nunique())\n",
    ">> 3\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The DataFrame inventory contains a list of types of t-shirts that your company makes. You want a list of the colors that your shirts come in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nprint(inventory.color)\\n>> ['blue', 'blue', 'blue', 'blue', 'blue', 'green', 'green', 'orange', 'orange', 'orange']\\nprint(inventory.color.unique())\\n>> ['blue', 'green', 'orange']\\n\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "print(inventory.color)\n",
    ">> ['blue', 'blue', 'blue', 'blue', 'blue', 'green', 'green', 'orange', 'orange', 'orange']\n",
    "print(inventory.color.unique())\n",
    ">> ['blue', 'green', 'orange']\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The general syntax for these calculations is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.column_name.command()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following table summarizes some common commands:\n",
    "\n",
    "    Command\t- Description\n",
    "    mean\t- Average of all values in column\n",
    "    std\t    - Standard deviation\n",
    "    median\t- Median\n",
    "    max\t    - Maximum value in column\n",
    "    min\t    - Minimum value in column\n",
    "    count\t- Number of values in column\n",
    "    nunique\t- Number of unique values in column\n",
    "    unique\t- List of unique values in column\n",
    "    \n",
    "Once more, we'll revisit our orders from ShoeFly.com. Our new batch of orders is in the DataFrame orders. Examine the first 10 rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      id first_name    last_name                         email     shoe_type  \\\n",
      "0  41874       Kyle         Peck          KylePeck71@gmail.com  ballet flats   \n",
      "1  31349  Elizabeth    Velazquez      EVelazquez1971@gmail.com         boots   \n",
      "2  43416      Keith     Saunders              KS4047@gmail.com       sandles   \n",
      "3  56054       Ryan      Sweeney     RyanSweeney14@outlook.com       sandles   \n",
      "4  77402      Donna  Blankenship              DB3807@gmail.com     stilettos   \n",
      "5  97148     Albert       Dillon       Albert.Dillon@gmail.com        wedges   \n",
      "6  19998     Judith       Hewitt      JudithHewitt98@gmail.com     stilettos   \n",
      "7  83290      Kayla       Hardin        Kayla.Hardin@gmail.com     stilettos   \n",
      "8  77867     Steven  Blankenship  Steven.Blankenship@gmail.com        wedges   \n",
      "9  54885      Carol   Mclaughlin              CM3415@gmail.com  ballet flats   \n",
      "\n",
      "  shoe_material shoe_color  price  \n",
      "0  faux-leather      black  385.0  \n",
      "1        fabric      brown  388.0  \n",
      "2       leather       navy  346.0  \n",
      "3        fabric      brown  344.0  \n",
      "4        fabric      brown  289.0  \n",
      "5        fabric      brown  266.0  \n",
      "6       leather      black  395.0  \n",
      "7       leather      white  241.0  \n",
      "8       leather       navy  266.0  \n",
      "9  faux-leather      brown  440.0  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "orders = pd.read_csv('orders.csv')\n",
    "print(orders.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our finance department wants to know the price of the most expensive pair of shoes purchased. Save your answer to the variable most_expensive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "493.0\n"
     ]
    }
   ],
   "source": [
    "most_expensive = orders.price.max()\n",
    "print(most_expensive)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our fashion department wants to know how many different colors of shoes we are selling. Save your answer to the variable num_colors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "num_colors = orders.shoe_color.nunique()\n",
    "print(num_colors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating Aggregate Functions I\n",
    "When we have a bunch of data, we often want to calculate aggregate statistics (mean, standard deviation, median, percentiles, etc.) over certain subsets of the data.\n",
    "\n",
    "In general, we use the following syntax to calculate aggregates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.groupby('column1').column2.measurement()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where:\n",
    "\n",
    "    column1 is the column that we want to group by ('student' in our example)\n",
    "    column2 is the column that we want to perform a measurement on (grade in our example)\n",
    "    measurement is the measurement function we want to apply (mean in our example)\n",
    "\n",
    "Let's return to our orders data from ShoeFly.com.\n",
    "\n",
    "In the previous exercise, our finance department wanted to know the most expensive shoe that we sold.\n",
    "\n",
    "Now, they want to know the most expensive shoe for each shoe_type (i.e., the most expensive boot, the most expensive ballet flat, etc.).\n",
    "\n",
    "Save your answer to the variable pricey_shoes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shoe_type\n",
      "ballet flats    481.0\n",
      "boots           478.0\n",
      "clogs           493.0\n",
      "sandles         456.0\n",
      "stilettos       487.0\n",
      "wedges          461.0\n",
      "Name: price, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "pricey_shoes = orders.groupby('shoe_type').price.max()\n",
    "print(pricey_shoes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What type of object is pricey_shoes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "print(type(pricey_shoes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "alculating Aggregate Functions II\n",
    "After using groupby, we often need to clean our resulting data.\n",
    "\n",
    "As we saw in the previous exercise, the groupby function creates a new Series, not a DataFrame. For our ShoeFly.com example, the indices of the Series were different values of shoe_type, and the name property was price.\n",
    "\n",
    "Usually, we'd prefer that those indices were actually a column. In order to get that, we can use reset_index(). This will transform our Series into a DataFrame and move the indices into their own column.\n",
    "\n",
    "Generally, you'll always see a groupby statement followed by reset_index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.groupby('column1').column2.measurement().reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modify your code from the previous exercise so that it ends with reset_index, which will change pricey_shoes into a DataFrame.\n",
    "\n",
    "Now, what type of object is pricey_shoes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      shoe_type  price\n",
      "0  ballet flats  481.0\n",
      "1         boots  478.0\n",
      "2         clogs  493.0\n",
      "3       sandles  456.0\n",
      "4     stilettos  487.0\n",
      "5        wedges  461.0\n",
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "pricey_shoes = orders.groupby('shoe_type').price.max().reset_index()\n",
    "print(pricey_shoes)\n",
    "print(type(pricey_shoes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating Aggregate Functions III\n",
    "Sometimes, the operation that you want to perform is more complicated than mean or count. In those cases, you can use the apply method and lambda functions, just like we did for individual column operations. Note that the input to our lambda function will always be a list of values.\n",
    "\n",
    "A great example of this is calculating percentiles. Suppose we have a DataFrame of employee information called df that has the following columns:\n",
    "\n",
    "    id: the employee's id number\n",
    "    name: the employee's name\n",
    "    wage: the employee's hourly wage\n",
    "    category: the type of work that the employee does\n",
    "\n",
    "Example: If we want to calculate the 75th percentile (i.e., the point at which 75% of employees have a lower wage and 25% have a higher wage) for each category, we can use the following combination of apply and a lambda function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n# np.percentile can calculate any percentile over an array of values\\nhigh_earners = df.groupby('category').wage\\n    .apply(lambda x: np.percentile(x, 75))\\n    .reset_index()\\n\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# np.percentile can calculate any percentile over an array of values\n",
    "high_earners = df.groupby('category').wage\n",
    "    .apply(lambda x: np.percentile(x, 75))\n",
    "    .reset_index()\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once more, we'll return to the data from ShoeFly.com. Our Marketing team says that it's important to have some affordably priced shoes available for every color of shoe that we sell.\n",
    "\n",
    "Let's calculate the 25th percentile for shoe price for each shoe_color to help Marketing decide if we have enough cheap shoes on sale. Save the data to the variable cheap_shoes.\n",
    "\n",
    "Note: Be sure to use reset_index() at the end of your query so that cheap_shoes is a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  shoe_color  price\n",
      "0      black    NaN\n",
      "1      brown  193.5\n",
      "2       navy  205.5\n",
      "3        red  250.0\n",
      "4      white  196.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kenne\\pythonfolder\\Miniconda3\\lib\\site-packages\\numpy\\lib\\function_base.py:4291: RuntimeWarning: Invalid value encountered in percentile\n",
      "  interpolation=interpolation)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "cheap_shoes = orders.groupby('shoe_color').price.apply(lambda x: np.percentile(x, 25)).reset_index()\n",
    "print(cheap_shoes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating Aggregate Functions IV\n",
    "Sometimes, we want to group by more than one column. We can easily do this by passing a list of column names into the groupby method.\n",
    "\n",
    "Imagine that we run a chain of stores and have data about the number of sales at different locations on different days:\n",
    "(table not showne here)\n",
    "\n",
    "We suspect that sales are different at different locations on different days of the week. In order to test this hypothesis, we could calculate the average sales for each store on each day of the week across multiple months. The code would look like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.groupby(['Location', 'Day of Week'])['Total Sales'].mean().reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At ShoeFly.com, our Purchasing team thinks that certain shoe_type/shoe_color combinations are particularly popular this year (for example, blue ballet flats are all the rage in Paris).\n",
    "\n",
    "Create a DataFrame with the total number of shoes of each shoe_type/shoe_color combination purchased. Save it to the variable shoe_counts.\n",
    "\n",
    "You should be able to do this using groupby and count().\n",
    "\n",
    "Note: When we're using count(), it doesn't really matter which column we perform the calculation on. You should use id in this example, but we would get the same answer if we used shoe_type or last_name.\n",
    "\n",
    "Remember to use reset_index() at the end of your code!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       shoe_type shoe_color  id\n",
      "0   ballet flats      black   2\n",
      "1   ballet flats      brown   5\n",
      "2   ballet flats        red   3\n",
      "3   ballet flats      white   5\n",
      "4          boots      black   3\n",
      "5          boots      brown   5\n",
      "6          boots       navy   6\n",
      "7          boots        red   2\n",
      "8          boots      white   3\n",
      "9          clogs      black   4\n",
      "10         clogs      brown   6\n",
      "11         clogs       navy   1\n",
      "12         clogs        red   4\n",
      "13         clogs      white   1\n",
      "14       sandles      black   1\n",
      "15       sandles      brown   4\n",
      "16       sandles       navy   5\n",
      "17       sandles        red   3\n",
      "18       sandles      white   4\n",
      "19     stilettos      black   5\n",
      "20     stilettos      brown   3\n",
      "21     stilettos       navy   2\n",
      "22     stilettos        red   2\n",
      "23     stilettos      white   2\n",
      "24        wedges      black   3\n",
      "25        wedges      brown   4\n",
      "26        wedges       navy   4\n",
      "27        wedges        red   5\n",
      "28        wedges      white   2\n"
     ]
    }
   ],
   "source": [
    "shoe_counts = orders.groupby(['shoe_type', 'shoe_color'])['id'].count().reset_index()\n",
    "print(shoe_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pivot Tables\n",
    "When we perform a groupby across multiple columns, we often want to change how our data is stored. \n",
    "\n",
    "In Pandas, the command for pivot is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ndf.pivot(columns='ColumnToPivot',\\n         index='ColumnToBeRows',\\n         values='ColumnToBeValues')\\n\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "df.pivot(columns='ColumnToPivot',\n",
    "         index='ColumnToBeRows',\n",
    "         values='ColumnToBeValues')\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just like with groupby, the output of a pivot command is a new DataFrame, but the indexing tends to be \"weird\", so we usually follow up with .reset_index().\n",
    "\n",
    "In the previous example, you created a DataFrame with the total number of shoes of each shoe_type/shoe_color combination purchased for ShoeFly.com.\n",
    "\n",
    "The purchasing manager complains that this DataFrame is confusing.\n",
    "\n",
    "Make it easier for her to compare purchases of different shoe colors of the same shoe type by creating a pivot table. Save your results to the variable shoe_counts_pivot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       shoe_type shoe_color  id\n",
      "0   ballet flats      black   2\n",
      "1   ballet flats      brown   5\n",
      "2   ballet flats        red   3\n",
      "3   ballet flats      white   5\n",
      "4          boots      black   3\n",
      "5          boots      brown   5\n",
      "6          boots       navy   6\n",
      "7          boots        red   2\n",
      "8          boots      white   3\n",
      "9          clogs      black   4\n",
      "10         clogs      brown   6\n",
      "11         clogs       navy   1\n",
      "12         clogs        red   4\n",
      "13         clogs      white   1\n",
      "14       sandles      black   1\n",
      "15       sandles      brown   4\n",
      "16       sandles       navy   5\n",
      "17       sandles        red   3\n",
      "18       sandles      white   4\n",
      "19     stilettos      black   5\n",
      "20     stilettos      brown   3\n",
      "21     stilettos       navy   2\n",
      "22     stilettos        red   2\n",
      "23     stilettos      white   2\n",
      "24        wedges      black   3\n",
      "25        wedges      brown   4\n",
      "26        wedges       navy   4\n",
      "27        wedges        red   5\n",
      "28        wedges      white   2\n",
      "shoe_color     shoe_type  black  brown  navy  red  white\n",
      "0           ballet flats    2.0    5.0   NaN  3.0    5.0\n",
      "1                  boots    3.0    5.0   6.0  2.0    3.0\n",
      "2                  clogs    4.0    6.0   1.0  4.0    1.0\n",
      "3                sandles    1.0    4.0   5.0  3.0    4.0\n",
      "4              stilettos    5.0    3.0   2.0  2.0    2.0\n",
      "5                 wedges    3.0    4.0   4.0  5.0    2.0\n"
     ]
    }
   ],
   "source": [
    "orders = pd.read_csv('orders.csv')\n",
    "\n",
    "shoe_counts = orders.groupby(['shoe_type', 'shoe_color']).id.count().reset_index()\n",
    "\n",
    "print(shoe_counts)\n",
    "\n",
    "shoe_counts_pivot = shoe_counts.pivot(\n",
    "    columns='shoe_color',\n",
    "    index='shoe_type',\n",
    "    values='id').reset_index()\n",
    "\n",
    "print(shoe_counts_pivot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Review\n",
    "This lesson introduced you to aggregates in Pandas. You learned:\n",
    "\n",
    "    How to perform aggregate statistics over individual rows with the same value using groupby.\n",
    "    How to rearrange a DataFrame into a pivot table, a great way to compare data across two dimensions.\n",
    "\n",
    "Let's examine some more data from ShoeFly.com. This time, we'll be looking at data about user visits to the website (the same dataset that you saw in the introduction to this lesson).\n",
    "\n",
    "The data is a DataFrame called user_visits. Use print and head() to examine the first few rows of the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      id first_name   last_name                       email         month  \\\n",
      "0  10043      Louis        Koch       LouisKoch43@gmail.com     3 - March   \n",
      "1  10150      Bruce        Webb     BruceWebb44@outlook.com     3 - March   \n",
      "2  10155   Nicholas     Hoffman  Nicholas.Hoffman@gmail.com  2 - February   \n",
      "3  10178    William         Key     William.Key@outlook.com     3 - March   \n",
      "4  10208      Karen        Bass            KB4971@gmail.com  2 - February   \n",
      "5  10260   Benjamin       Ochoa  Benjamin.Ochoa@outlook.com   1 - January   \n",
      "6  10271     Gerald     Aguilar    Gerald.Aguilar@gmail.com     3 - March   \n",
      "7  10278    Melissa     Lambert   Melissa.Lambert@gmail.com  2 - February   \n",
      "8  10320       Adam  Strickland   Adam.Strickland@gmail.com     3 - March   \n",
      "9  10389      Ethan       Payne    EthanPayne26@outlook.com  2 - February   \n",
      "\n",
      "  utm_source  \n",
      "0      yahoo  \n",
      "1    twitter  \n",
      "2     google  \n",
      "3      yahoo  \n",
      "4     google  \n",
      "5    twitter  \n",
      "6     google  \n",
      "7      email  \n",
      "8      email  \n",
      "9   facebook  \n"
     ]
    }
   ],
   "source": [
    "user_visits = pd.read_csv('page_visits.csv')\n",
    "print(user_visits.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The column utm_source contains information about how users got to ShoeFly's homepage. For instance, if utm_source = Facebook, then the user came to ShoeFly by clicking on an ad on Facebook.com.\n",
    "\n",
    "Use a groupby statement to calculate how many visits came from each of the different sources. Save your answer to the variable click_source.\n",
    "\n",
    "Remember to use reset_index()!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  utm_source   id\n",
      "0      email  462\n",
      "1   facebook  823\n",
      "2     google  543\n",
      "3    twitter  415\n",
      "4      yahoo  757\n",
      "month utm_source  1 - January  2 - February  3 - March\n",
      "0          email           43           147        272\n",
      "1       facebook          404           263        156\n",
      "2         google          127           196        220\n",
      "3        twitter          164           154         97\n",
      "4          yahoo          262           240        255\n"
     ]
    }
   ],
   "source": [
    "click_source = user_visits.groupby('utm_source').id.count().reset_index()\n",
    "print(click_source)\n",
    "\n",
    "click_source_by_month = user_visits.groupby(['utm_source', 'month']).id.count().reset_index()\n",
    "\n",
    "click_source_by_month_pivot = click_source_by_month.pivot(\n",
    "    columns='month',\n",
    "    index='utm_source',\n",
    "    values='id').reset_index()\n",
    "\n",
    "print(click_source_by_month_pivot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
